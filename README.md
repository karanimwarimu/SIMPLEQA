# Local QB (Mistral 7B) Flask App ğŸš€

This project runs a **local AI model (Mistral 7B)** with a **Flask web server**, and exposes an API endpoint for simple text generation.

---

## ğŸ”§ Features
- Flask web server with `/ask` POST endpoint
- Local inference using [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
- Simple HTML frontend (`web.html`)
- CORS enabled for cross-origin requests

---

## ğŸ“‚ Project Structure
project/
â”‚â”€â”€ app.py                 # Flask server
â”‚â”€â”€ text_gen_PROMAX.py     # Wrapper for llama-cpp model
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚â”€â”€ .gitignore
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ web.html       # Frontend page
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ webcss.css     # Example CSS file
â”‚       â””â”€â”€ script.js      # Example JS file
â”‚
â””â”€â”€ model (to be generated automatically)

---

## âš¡ Setup Instructions

### 1. Clone the repo
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
```

### 2. Create & activate virtual environment
bash
Copy code
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows

### 3. Install dependencies
bash
Copy code
pip install -r requirements.txt

### 4. Add your model
Download a Mistral 7B gguf model and place it inside a models/ folder (ignored by git).
or it will be generated automatically on starting the app

Example:
bash
Copy code
models/mistral-7b-instruct-v0.1.Q4_K_M.gguf

### 5. Run the Flask server
bash
Copy code
python app.py
The app runs at http://your IP Address:5000.

also ensure the webserver.html , the api points to the machine hosting the page , change to own ip address if using from othe rdevices :   
           try {
                const res = await fetch('http://127.0.0.1:5000/ask', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prompt })
                });

###6 . Access the API:
 send a prompt affter starting the server using python second_app.py and accesing the web page 

###ğŸŒ Optional: Public Access
To expose your server online :

Use : Cloudflare Tunnel or you can use NGRok(see more information ... added later)

Or host on a VPS with GPU
